{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp spe2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPE2Vec\n",
    "\n",
    ">  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import gensim\n",
    "\n",
    "\n",
    "class Corpus(object):\n",
    "    '''\n",
    "    *filename*: A file that stores SMILES line-by-line.\n",
    "    \n",
    "    *tokenizer*: SPE tokenizer\n",
    "    \n",
    "    *dropout*: SPE dropout, default = 0\n",
    "    '''\n",
    "    def __init__(self, infile, tokenizer, isdir=False, dropout=0):\n",
    "        self.infile = infile\n",
    "        self.tokenizer = tokenizer\n",
    "        self.dropout = dropout\n",
    "        self.isdir = isdir\n",
    " \n",
    "    def __iter__(self):\n",
    "        if self.isdir:\n",
    "            for fname in os.listdir(self.infile):\n",
    "                for smi in open(os.path.join(self.infile, fname)):\n",
    "                    yield self.tokenizer.tokenize(smi, dropout=self.dropout).split(' ')\n",
    "        else:\n",
    "            for smi in open(self.infile):\n",
    "                yield self.tokenizer.tokenize(smi, dropout=self.dropout).split(' ')\n",
    "    \n",
    "def learn_spe2vec(corpus, outfile=None, \n",
    "                  vector_size=100, window=10, min_count=10, n_jobs = 1, method = 'skip-gram', \n",
    "                  **kwargs):\n",
    "    '''\n",
    "    Train a spe2vec model.\n",
    "    \n",
    "    *corpus*: an instance of `Class Corpus()`\n",
    "    \n",
    "    *outfile*: str, name of the spe2vec model file.\n",
    "    \n",
    "    *vector_size*: dimensions of embedding.\n",
    "    \n",
    "    *window*: number of tokens considered as context\n",
    "    \n",
    "    *min_count*: number of occurrences a token should have to be considered in training\n",
    "    \n",
    "    *n_jobs*: number of cpu cores used for training.\n",
    "    \n",
    "    *method*: modeling method, choose from ['cbow', 'skip-gram']\n",
    "    \n",
    "    More training parameter can be found https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec\n",
    "    '''\n",
    "    \n",
    "    if method.lower() == 'skip-gram':\n",
    "        sg = 1\n",
    "    elif method.lower() == 'cbow':\n",
    "        sg = 0\n",
    "    else:\n",
    "        raise ValueError(\"Invalid option,  choose from ['cbow', 'skip-gram']\")\n",
    "    \n",
    "    model = gensim.models.Word2Vec(corpus, size=vector_size, window=window, min_count=min_count, workers=n_jobs, sg=sg,\n",
    "                              **kwargs)\n",
    "    \n",
    "    if outfile:\n",
    "        model.save(outfile)\n",
    "        \n",
    "    return model\n",
    "\n",
    "def load_spe2vec(model_path):\n",
    "    return gensim.models.Word2Vec.load(model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "class SPE2Vec(object):\n",
    "    def __init__(self, model_path, tokenizer):\n",
    "        self.model = gensim.models.Word2Vec.load(model_path)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_keys = set(self.model.wv.vocab.keys())\n",
    "        \n",
    "        #get the vector for unknown tokens. simply averge the vectors of all known tokens.\n",
    "        import numpy as np\n",
    "        \n",
    "        vectors = []\n",
    "        for word in self.model.wv.vocab:\n",
    "            vectors.append(self.model.wv[word])        \n",
    "        self.unknown = np.mean(vectors, axis=0)\n",
    "    \n",
    "    def tokenize(self, smi, dropout=0):\n",
    "        '''\n",
    "        tokenize SMILES into substructure tokens.\n",
    "        '''\n",
    "        return self.tokenizer.tokenize(smi, dropout)\n",
    "    \n",
    "    def smiles2vec(self, smi, dropout=0):\n",
    "        '''\n",
    "        Generate a vector for a SMILES. The vector is simply a sum of vectors for individual tokens.\n",
    "        \n",
    "        The Unknown token will be skipped\n",
    "        '''\n",
    "        \n",
    "        tokens = self.tokenizer.tokenize(smi, dropout).split(' ')\n",
    "#         vec=[]\n",
    "#         for tok in tokens:\n",
    "#             if tok in self.token_keys:\n",
    "#                 vec.append(self.model.wv[tok])\n",
    "        \n",
    "        return np.mean([self.model.wv[tok] for tok in tokens if tok in self.token_keys], axis=0)\n",
    "    \n",
    "    def spe2vec(self, smi, dropout=0, skip_unknown=False):\n",
    "        '''\n",
    "        Generate a list of vectors (np.array). Each vector is spe vector of each token.\n",
    "        \n",
    "        The unknown token will be represented by the mean of all token vectors from the model.\n",
    "        '''\n",
    "        \n",
    "        token_keys = set(self.model.wv.vocab.keys())\n",
    "        tokens = self.tokenizer.tokenize(smi, dropout).split(' ')\n",
    "        \n",
    "        if skip_unknown:\n",
    "            vec = [self.model.wv[tok] for tok in tokens if tok in self.token_keys]\n",
    "        else:\n",
    "            vec = [self.model.wv[tok] if tok in self.token_keys else self.unknown for tok in tokens]\n",
    "        \n",
    "        return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "file = '../experiments/data/smiles_toy.smi'\n",
    "filedir = '../experiments/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import codecs\n",
    "from SmilesPE.tokenizer import *\n",
    "spe_vob= codecs.open('../SPE_ChEMBL.txt')\n",
    "spe = SPE_Tokenizer(spe_vob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.81 s, sys: 19.6 ms, total: 2.83 s\n",
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%%time\n",
    "corpus = Corpus(file, tokenizer = spe) # a memory-friendly iterator\n",
    "model = learn_spe2vec(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=3114, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "model = load_spe2vec('../experiments/results/spe_model.bin')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = SPE2Vec('../experiments/results/spe_model.bin', spe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c1ccccc1'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.tokenize('c1ccccc1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.smiles2vec('c1ccccc1') == model.wv['c1ccccc1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c1ccccc1 [dum]'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.tokenize('c1ccccc1[dum]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.00324177, -0.18124679,  0.1894573 ,  0.29736474, -0.14143717,\n",
       "        -0.03290153, -0.31891045,  0.16373567, -0.12413523, -0.08658446,\n",
       "        -0.23956653,  0.05335753,  0.18146366, -0.17212407, -0.17879114,\n",
       "        -0.01039552, -0.00274071,  0.01653983,  0.08432296, -0.15634526,\n",
       "         0.29629305, -0.16786121,  0.06479991,  0.34462902, -0.11052489,\n",
       "        -0.13513446,  0.16418819, -0.21508686, -0.01842665, -0.15818536,\n",
       "        -0.05421342,  0.2041645 ,  0.14783993, -0.00653112, -0.19034739,\n",
       "        -0.11876111,  0.12208337, -0.0743893 ,  0.03400969,  0.04422404,\n",
       "        -0.10224582,  0.34490895,  0.12326851, -0.08695894, -0.08150315,\n",
       "         0.09907438,  0.28797793,  0.15912676,  0.15228626, -0.164707  ,\n",
       "         0.33839643, -0.04265443, -0.11858924,  0.10059267, -0.24335982,\n",
       "        -0.02948368,  0.53029126,  0.2448303 ,  0.11335112,  0.01153868,\n",
       "        -0.01010862, -0.06406022, -0.01338368, -0.18424016,  0.03580371,\n",
       "         0.18463984,  0.15326728, -0.15144381, -0.0136445 , -0.01842183,\n",
       "        -0.01942809, -0.40844846, -0.3803786 ,  0.06027165,  0.1963685 ,\n",
       "         0.17956594,  0.43164128,  0.15884452, -0.05903239, -0.12084594,\n",
       "        -0.3421759 ,  0.09406078, -0.1743247 , -0.07216409, -0.36593992,\n",
       "         0.40148914,  0.06790256,  0.00517231, -0.03673836,  0.15515997,\n",
       "         0.05461619,  0.34084585,  0.18900603, -0.02054791, -0.3929679 ,\n",
       "         0.02184797,  0.63548833,  0.15527408, -0.04567065, -0.04842073],\n",
       "       dtype=float32),\n",
       " array([ 0.02790021,  0.10730326,  0.03549408,  0.29470772, -0.12696277,\n",
       "        -0.17874953, -0.14898987, -0.01619787,  0.05362142,  0.04036978,\n",
       "         0.01510846, -0.10854848,  0.11008958, -0.19785249,  0.1081469 ,\n",
       "         0.09286551,  0.02338837,  0.1321442 , -0.05999994, -0.2136096 ,\n",
       "         0.21495438, -0.01279392,  0.05619901,  0.30066583, -0.11601048,\n",
       "         0.11202455,  0.09189299, -0.04536214,  0.08480586, -0.12446755,\n",
       "        -0.15830296,  0.2975169 , -0.00044652, -0.1067949 , -0.13344204,\n",
       "        -0.22030011,  0.06412205, -0.1179566 ,  0.06744988, -0.04845589,\n",
       "         0.03443845,  0.0760651 , -0.00702342, -0.15744554, -0.03714913,\n",
       "        -0.08268054, -0.0328347 ,  0.03743869,  0.09009899, -0.04988885,\n",
       "         0.11295835, -0.10700615, -0.16241288, -0.13567367,  0.05850025,\n",
       "        -0.00316843,  0.27738932,  0.00349046, -0.10917356,  0.05029386,\n",
       "         0.07648825,  0.03960387,  0.033869  , -0.11763074, -0.04516807,\n",
       "        -0.02431042, -0.03469331, -0.00660511,  0.12014298, -0.19823211,\n",
       "         0.10597764, -0.12160178, -0.09303743,  0.11049194, -0.04670779,\n",
       "         0.18275349,  0.14410464,  0.10586358,  0.13328582, -0.10212968,\n",
       "        -0.06977161,  0.02081367, -0.14675769, -0.23168154, -0.02661432,\n",
       "         0.12376714,  0.1612328 ,  0.12798673,  0.03350298, -0.02620391,\n",
       "         0.01916613,  0.06788647, -0.00453908, -0.07472298, -0.19086805,\n",
       "         0.08175525,  0.13679074,  0.02294019, -0.08880823, -0.11674882],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.spe2vec('c1ccccc1[dum]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.00324177, -0.18124679,  0.1894573 ,  0.29736474, -0.14143717,\n",
       "        -0.03290153, -0.31891045,  0.16373567, -0.12413523, -0.08658446,\n",
       "        -0.23956653,  0.05335753,  0.18146366, -0.17212407, -0.17879114,\n",
       "        -0.01039552, -0.00274071,  0.01653983,  0.08432296, -0.15634526,\n",
       "         0.29629305, -0.16786121,  0.06479991,  0.34462902, -0.11052489,\n",
       "        -0.13513446,  0.16418819, -0.21508686, -0.01842665, -0.15818536,\n",
       "        -0.05421342,  0.2041645 ,  0.14783993, -0.00653112, -0.19034739,\n",
       "        -0.11876111,  0.12208337, -0.0743893 ,  0.03400969,  0.04422404,\n",
       "        -0.10224582,  0.34490895,  0.12326851, -0.08695894, -0.08150315,\n",
       "         0.09907438,  0.28797793,  0.15912676,  0.15228626, -0.164707  ,\n",
       "         0.33839643, -0.04265443, -0.11858924,  0.10059267, -0.24335982,\n",
       "        -0.02948368,  0.53029126,  0.2448303 ,  0.11335112,  0.01153868,\n",
       "        -0.01010862, -0.06406022, -0.01338368, -0.18424016,  0.03580371,\n",
       "         0.18463984,  0.15326728, -0.15144381, -0.0136445 , -0.01842183,\n",
       "        -0.01942809, -0.40844846, -0.3803786 ,  0.06027165,  0.1963685 ,\n",
       "         0.17956594,  0.43164128,  0.15884452, -0.05903239, -0.12084594,\n",
       "        -0.3421759 ,  0.09406078, -0.1743247 , -0.07216409, -0.36593992,\n",
       "         0.40148914,  0.06790256,  0.00517231, -0.03673836,  0.15515997,\n",
       "         0.05461619,  0.34084585,  0.18900603, -0.02054791, -0.3929679 ,\n",
       "         0.02184797,  0.63548833,  0.15527408, -0.04567065, -0.04842073],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.spe2vec('c1ccccc1[dum]',skip_unknown=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
