---

title: SMILES Pair Encoding (SmilesPE)

keywords: fastai
sidebar: home_sidebar

summary: "Tokenize SMILES (Simplified Molecular-Input Line-Entry System) into substructure units. "
description: "Tokenize SMILES (Simplified Molecular-Input Line-Entry System) into substructure units. "
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: notebooks_build/00_SmilesPE.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    {% raw %}
        
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="atomwise_tokenizer" class="doc_header"><code>atomwise_tokenizer</code><a href="https://github.com/XinhaoLi74/SMILES Pair Encoding/tree/master/SmilesPE/SmilesPE.py#L22" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>atomwise_tokenizer</code>(<strong><code>smi</code></strong>, <strong><code>exclusive_tokens</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Tokenize a SMILES molecule at atom-level:
    (1) 'Br' and 'Cl' are two-character tokens
    (2) Symbols with bracket are considered as tokens</p>
<p>exclusive_tokens: A list of specifical symbols with bracket you want to keep. e.g., ['[C@@H]', '[nH]'].
Other symbols with bracket will be replaced by '[UNK]'. default is None.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="randomize_smiles" class="doc_header"><code>randomize_smiles</code><a href="https://github.com/XinhaoLi74/SMILES Pair Encoding/tree/master/SmilesPE/SmilesPE.py#L44" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>randomize_smiles</code>(<strong><code>smiles</code></strong>)</p>
</blockquote>
<p>Generate a new SMILES string for the same molecule.
Perform a randomization of a SMILES string must be RDKit sanitizable.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_vocabulary" class="doc_header"><code>get_vocabulary</code><a href="https://github.com/XinhaoLi74/SMILES Pair Encoding/tree/master/SmilesPE/SmilesPE.py#L55" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_vocabulary</code>(<strong><code>smiles</code></strong>, <strong><code>augmentation</code></strong>=<em><code>0</code></em>, <strong><code>exclusive_tokens</code></strong>=<em><code>False</code></em>)</p>
</blockquote>
<p>Read text and return dictionary that encodes vocabulary</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="update_pair_statistics" class="doc_header"><code>update_pair_statistics</code><a href="https://github.com/XinhaoLi74/SMILES Pair Encoding/tree/master/SmilesPE/SmilesPE.py#L76" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>update_pair_statistics</code>(<strong><code>pair</code></strong>, <strong><code>changed</code></strong>, <strong><code>stats</code></strong>, <strong><code>indices</code></strong>)</p>
</blockquote>
<p>Minimally update the indices and frequency of symbol pairs
if we merge a pair of symbols, only pairs that overlap with occurrences
of this pair are affected, and need to be updated.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_pair_statistics" class="doc_header"><code>get_pair_statistics</code><a href="https://github.com/XinhaoLi74/SMILES Pair Encoding/tree/master/SmilesPE/SmilesPE.py#L133" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_pair_statistics</code>(<strong><code>vocab</code></strong>)</p>
</blockquote>
<p>Count frequency of all symbol pairs, and create index</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="replace_pair" class="doc_header"><code>replace_pair</code><a href="https://github.com/XinhaoLi74/SMILES Pair Encoding/tree/master/SmilesPE/SmilesPE.py#L152" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>replace_pair</code>(<strong><code>pair</code></strong>, <strong><code>vocab</code></strong>, <strong><code>indices</code></strong>)</p>
</blockquote>
<p>Replace all occurrences of a symbol pair ('A', 'B') with a new symbol 'AB'</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="prune_stats" class="doc_header"><code>prune_stats</code><a href="https://github.com/XinhaoLi74/SMILES Pair Encoding/tree/master/SmilesPE/SmilesPE.py#L176" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>prune_stats</code>(<strong><code>stats</code></strong>, <strong><code>big_stats</code></strong>, <strong><code>threshold</code></strong>)</p>
</blockquote>
<p>Prune statistics dict for efficiency of max()
The frequency of a symbol pair never increases, so pruning is generally safe
(until we the most frequent pair is less frequent than a pair we previously pruned)
big_stats keeps full statistics for when we need to access pruned items</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="learn_SPE" class="doc_header"><code>learn_SPE</code><a href="https://github.com/XinhaoLi74/SMILES Pair Encoding/tree/master/SmilesPE/SmilesPE.py#L190" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>learn_SPE</code>(<strong><code>infile</code></strong>, <strong><code>outfile</code></strong>, <strong><code>num_symbols</code></strong>, <strong><code>min_frequency</code></strong>=<em><code>2</code></em>, <strong><code>augmentation</code></strong>=<em><code>0</code></em>, <strong><code>verbose</code></strong>=<em><code>False</code></em>, <strong><code>total_symbols</code></strong>=<em><code>False</code></em>)</p>
</blockquote>
<p>Learn num_symbols SPE operations from infile and write to outfile.</p>
<p>infile: a list of SMILES
num_symbols: maximum total number of SPE symbols
min_frequency: the minimum frequency of SPE symbols appears.
augmentation: times of SMILES augmentation
verbose: print the merging process
total_symbols: if true; the maximum total of SPE symbols = num_symbols - number of atom-level tokens</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SPE_Tokenizer" class="doc_header"><code>class</code> <code>SPE_Tokenizer</code><a href="https://github.com/XinhaoLi74/SMILES Pair Encoding/tree/master/SmilesPE/SmilesPE.py#L253" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SPE_Tokenizer</code>(<strong><code>codes</code></strong>, <strong><code>merges</code></strong>=<em><code>-1</code></em>, <strong><code>glossaries</code></strong>=<em><code>None</code></em>, <strong><code>exclusive_tokens</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Tokenize SMILES based on the learned SPE tokens.</p>
<p>codes: output file of <code>learn_SPE()</code>
merge
exclusive_tokens: argument that passes to  <code>atomwise_tokenizer()</code>
glossaries: argument that passes to <code>isolate_glossary()</code></p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="encode" class="doc_header"><code>encode</code><a href="https://github.com/XinhaoLi74/SMILES Pair Encoding/tree/master/SmilesPE/SmilesPE.py#L308" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>encode</code>(<strong><code>orig</code></strong>, <strong><code>bpe_codes</code></strong>, <strong><code>bpe_codes_reverse</code></strong>, <strong><code>cache</code></strong>, <strong><code>exclusive_tokens</code></strong>=<em><code>None</code></em>, <strong><code>glossaries_regex</code></strong>=<em><code>None</code></em>, <strong><code>dropout</code></strong>=<em><code>0</code></em>)</p>
</blockquote>
<p>Encode word based on list of SPE merge operations, which are applied consecutively.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="isolate_glossary" class="doc_header"><code>isolate_glossary</code><a href="https://github.com/XinhaoLi74/SMILES Pair Encoding/tree/master/SmilesPE/SmilesPE.py#L357" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>isolate_glossary</code>(<strong><code>word</code></strong>, <strong><code>glossary</code></strong>)</p>
</blockquote>
<p>Isolate a glossary present inside a word.
Returns a list of subwords. In which all 'glossary' glossaries are isolated
For example, if 'USA' is the glossary and '1934USABUSA' the word, the return value is:
    ['1934', 'USA', 'B', 'USA']</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}
</div>
 

